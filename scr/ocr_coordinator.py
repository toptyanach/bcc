"""
OCR Coordinator - –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö OCR –¥–≤–∏–∂–∫–æ–≤
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é PaddleOCR, Tesseract, TrOCR –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏
"""

import json
import traceback
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from PIL import Image
import tempfile

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º OCR –º–æ–¥—É–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
try:
    from ocr_paddle import run_paddle, get_plaintext
    PADDLE_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è PaddleOCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    PADDLE_AVAILABLE = False

try:
    from ocr_baseline import run_tesseract, run_tesseract_with_data
    TESSERACT_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Tesseract –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    TESSERACT_AVAILABLE = False

try:
    from ocr_trocr import run_trocr
    TROCR_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è TrOCR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    TROCR_AVAILABLE = False

try:
    from extract import extract_fields_from_paddle
    EXTRACT_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Extract –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    EXTRACT_AVAILABLE = False

try:
    from metrics import cer, wer, normalized_levenshtein, field_metrics
    METRICS_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Metrics –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    METRICS_AVAILABLE = False


class OCRCoordinator:
    """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö OCR –¥–≤–∏–∂–∫–æ–≤"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞"""
        self.engines = {
            'PaddleOCR': {
                'available': PADDLE_AVAILABLE,
                'function': self._run_paddle_ocr,
                'description': 'PaddleOCR - –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã'
            },
            'Tesseract': {
                'available': TESSERACT_AVAILABLE,
                'function': self._run_tesseract_ocr,
                'description': 'Tesseract - –±—ã—Å—Ç—Ä—ã–π –±–∞–∑–æ–≤—ã–π OCR'
            },
            'TrOCR': {
                'available': TROCR_AVAILABLE,
                'function': self._run_trocr_ocr,
                'description': 'TrOCR - AI-–º–æ–¥–µ–ª—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤'
            }
        }

    def get_available_engines(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö OCR –¥–≤–∏–∂–∫–æ–≤"""
        return [name for name, config in self.engines.items() if config['available']]

    def get_engine_info(self) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–≤–∏–∂–∫–∞—Ö"""
        return {
            name: {
                'available': config['available'],
                'description': config['description']
            }
            for name, config in self.engines.items()
        }

    def _run_paddle_ocr(self, image_path: str, **kwargs) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ PaddleOCR"""
        if not PADDLE_AVAILABLE:
            raise RuntimeError("PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        language = kwargs.get('language', 'ru')

        # –ó–∞–ø—É—Å–∫–∞–µ–º OCR
        ocr_output = run_paddle(image_path, lang=language)
        raw_text = get_plaintext(ocr_output)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª—è –µ—Å–ª–∏ –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω
        extracted_fields = {}
        if EXTRACT_AVAILABLE:
            try:
                extracted_fields = extract_fields_from_paddle(ocr_output)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π: {e}")

        return {
            'engine': 'PaddleOCR',
            'raw_text': raw_text,
            'ocr_data': ocr_output,
            'extracted_fields': extracted_fields,
            'total_items': len(ocr_output) if ocr_output else 0,
            'avg_confidence': sum(item.get('conf', 0) for item in ocr_output) / len(ocr_output) if ocr_output else 0
        }

    def _run_tesseract_ocr(self, image_path: str, **kwargs) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Tesseract OCR"""
        if not TESSERACT_AVAILABLE:
            raise RuntimeError("Tesseract –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        language = kwargs.get('language', 'eng')  # –ò–∑–º–µ–Ω–µ–Ω –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ä—É—Å—Å–∫–∏–π

        # –ó–∞–ø—É—Å–∫–∞–µ–º OCR —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —è–∑—ã–∫–∞
        raw_text = run_tesseract(image_path, lang=None)  # None = –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        ocr_data = run_tesseract_with_data(image_path, lang=None)

        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π –¥–ª—è Tesseract
        extracted_fields = self._extract_fields_simple(raw_text)

        return {
            'engine': 'Tesseract',
            'raw_text': raw_text,
            'ocr_data': ocr_data,
            'extracted_fields': extracted_fields,
            'total_items': len(ocr_data) if ocr_data else 0,
            'avg_confidence': sum(item.get('conf', 0) for item in ocr_data) / len(ocr_data) if ocr_data else 0
        }

    def _run_trocr_ocr(self, image_path: str, **kwargs) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ TrOCR"""
        if not TROCR_AVAILABLE:
            raise RuntimeError("TrOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        # –ó–∞–ø—É—Å–∫–∞–µ–º OCR
        raw_text = run_trocr(image_path)

        # TrOCR –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        extracted_fields = self._extract_fields_simple(raw_text)

        return {
            'engine': 'TrOCR',
            'raw_text': raw_text,
            'ocr_data': [],
            'extracted_fields': extracted_fields,
            'total_items': 1,
            'avg_confidence': 0.85  # TrOCR –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç confidence
        }

    def _extract_fields_simple(self, text: str) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
        import re
        from datetime import datetime

        fields = {}

        # –î–∞—Ç—ã (–ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫)
        date_patterns = [
            r'\b(\d{1,2})[.\-/](\d{1,2})[.\-/](\d{4})\b',
            r'\b(\d{4})[.\-/](\d{1,2})[.\-/](\d{1,2})\b'
        ]

        for pattern in date_patterns:
            matches = re.findall(pattern, text)
            if matches:
                try:
                    if len(matches[0][0]) == 4:  # YYYY-MM-DD
                        date_obj = datetime(int(matches[0][0]), int(matches[0][1]), int(matches[0][2]))
                    else:  # DD.MM.YYYY
                        date_obj = datetime(int(matches[0][2]), int(matches[0][1]), int(matches[0][0]))
                    fields['date'] = date_obj.strftime('%Y-%m-%d')
                    break
                except ValueError:
                    continue

        # –°—É–º–º—ã
        sum_pattern = r'(\d{1,3}(?:[\s,]\d{3})*(?:[.,]\d{1,2})?)\s*(?:—Ä—É–±|—Ä—É–±–ª–µ–π|—Ä\.|‚ÇΩ)'
        sum_matches = re.findall(sum_pattern, text, re.IGNORECASE)
        if sum_matches:
            try:
                sum_str = sum_matches[0].replace(' ', '').replace(',', '.')
                fields['sum'] = float(sum_str)
            except ValueError:
                pass

        # –¢–µ–ª–µ—Ñ–æ–Ω—ã
        phone_pattern = r'(?:\+7|8|7)?[\s\-]?\(?\d{3}\)?[\s\-]?\d{3}[\s\-]?\d{2}[\s\-]?\d{2}'
        phone_matches = re.findall(phone_pattern, text)
        if phone_matches:
            phone = re.sub(r'[^\d+]', '', phone_matches[0])
            if len(phone) >= 10:
                fields['phone'] = phone

        # Email
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_matches = re.findall(email_pattern, text, re.IGNORECASE)
        if email_matches:
            fields['email'] = email_matches[0].lower()

        # –ò–ù–ù
        inn_pattern = r'\b\d{10}\b|\b\d{12}\b'
        inn_matches = re.findall(inn_pattern, text)
        if inn_matches:
            fields['inn'] = inn_matches[0]

        fields['raw_text'] = text
        fields['total_chars'] = len(text)
        fields['total_words'] = len(text.split())

        return fields

    def recommend_engine(self, image_path: str) -> Dict[str, Any]:
        """
        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è OCR –¥–≤–∏–∂–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
        """
        try:
            from PIL import Image

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path)
            width, height = image.size
            total_pixels = width * height
            aspect_ratio = width / height if height > 0 else 1

            file_path = Path(image_path)
            file_size = file_path.stat().st_size

            recommendation = {
                'image_stats': {
                    'width': width,
                    'height': height,
                    'total_pixels': total_pixels,
                    'aspect_ratio': round(aspect_ratio, 2),
                    'file_size_mb': round(file_size / 1024 / 1024, 2)
                },
                'recommendations': []
            }

            # –õ–æ–≥–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            if total_pixels > 2000000:  # –ë–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                recommendation['recommendations'].append({
                    'engine': 'PaddleOCR',
                    'priority': 1,
                    'reason': '–ë–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º - PaddleOCR –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏'
                })
                recommendation['recommendations'].append({
                    'engine': 'Tesseract',
                    'priority': 2,
                    'reason': '–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'
                })
                recommendation['recommendations'].append({
                    'engine': 'TrOCR',
                    'priority': 3,
                    'reason': '–ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è - TrOCR –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ —Ç–µ–∫—Å—Ç–∞'
                })
            elif aspect_ratio > 5 or aspect_ratio < 0.2:  # –î–ª–∏–Ω–Ω—ã–µ —É–∑–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                recommendation['recommendations'].append({
                    'engine': 'TrOCR',
                    'priority': 1,
                    'reason': '–£–∑–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –≤–µ—Ä–æ—è—Ç–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Ç–µ–∫—Å—Ç–∞ - –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è TrOCR'
                })
                recommendation['recommendations'].append({
                    'engine': 'PaddleOCR',
                    'priority': 2,
                    'reason': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞'
                })
            elif total_pixels < 500000:  # –ù–µ–±–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                recommendation['recommendations'].append({
                    'engine': 'TrOCR',
                    'priority': 1,
                    'reason': '–ù–µ–±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - TrOCR –º–æ–∂–µ—Ç –¥–∞—Ç—å —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ'
                })
                recommendation['recommendations'].append({
                    'engine': 'PaddleOCR',
                    'priority': 2,
                    'reason': '–ù–∞–¥–µ–∂–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞'
                })
            else:  # –°—Ä–µ–¥–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                recommendation['recommendations'].append({
                    'engine': 'PaddleOCR',
                    'priority': 1,
                    'reason': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'
                })
                recommendation['recommendations'].append({
                    'engine': 'Tesseract',
                    'priority': 2,
                    'reason': '–•–æ—Ä–æ—à–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'
                })
                recommendation['recommendations'].append({
                    'engine': 'TrOCR',
                    'priority': 3,
                    'reason': '–ú–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–æ–π—Ç–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤'
                })

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–∫–æ–≤
            for rec in recommendation['recommendations']:
                engine = rec['engine']
                if engine in self.engines:
                    rec['available'] = self.engines[engine]['available']
                    if not rec['available']:
                        rec['reason'] += ' (–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù)'

            return recommendation

        except Exception as e:
            return {
                'error': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}',
                'recommendations': [{
                    'engine': 'PaddleOCR',
                    'priority': 1,
                    'reason': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é'
                }]
            }

    def process_document(
        self,
        image_path: str,
        engine: str = 'PaddleOCR',
        language: str = 'ru',
        use_llm: bool = False,
        confidence_threshold: float = 0.5,
        **kwargs
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–º OCR –¥–≤–∏–∂–∫–æ–º

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            engine: –ù–∞–∑–≤–∞–Ω–∏–µ OCR –¥–≤–∏–∂–∫–∞
            language: –Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            use_llm: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ LLM –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É
            confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            if engine not in self.engines:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–≤–∏–∂–æ–∫: {engine}")

            if not self.engines[engine]['available']:
                raise RuntimeError(f"–î–≤–∏–∂–æ–∫ {engine} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª
            if not Path(image_path).exists():
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")

            # –ó–∞–ø—É—Å–∫–∞–µ–º OCR
            ocr_function = self.engines[engine]['function']
            result = ocr_function(image_path, language=language, **kwargs)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            result.update({
                'processing_params': {
                    'engine': engine,
                    'language': language,
                    'use_llm': use_llm,
                    'confidence_threshold': confidence_threshold
                },
                'file_info': {
                    'path': image_path,
                    'size': Path(image_path).stat().st_size,
                    'name': Path(image_path).name
                },
                'timestamp': str(Path(image_path).stat().st_mtime),
                'success': True
            })

            # TODO: LLM –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞
            if use_llm:
                result['llm_postprocessed'] = False
                result['llm_note'] = "LLM –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞"

            return result

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'traceback': traceback.format_exc(),
                'engine': engine
            }

    def compare_engines(
        self,
        image_path: str,
        engines: List[str] = None,
        language: str = 'ru',
        **kwargs
    ) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö OCR –¥–≤–∏–∂–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            engines: –°–ø–∏—Å–æ–∫ –¥–≤–∏–∂–∫–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            language: –Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if engines is None:
            engines = self.get_available_engines()

        results = {}
        comparison_metrics = {}

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–º –¥–≤–∏–∂–∫–æ–º
        for engine in engines:
            if engine in self.engines and self.engines[engine]['available']:
                print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {engine}...")
                result = self.process_document(
                    image_path=image_path,
                    engine=engine,
                    language=language,
                    **kwargs
                )
                results[engine] = result

        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if len(results) > 1 and METRICS_AVAILABLE:
            texts = {engine: result.get('raw_text', '') for engine, result in results.items() if result.get('success')}

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –ø–æ–ø–∞—Ä–Ω–æ
            for engine1 in texts:
                for engine2 in texts:
                    if engine1 != engine2:
                        key = f"{engine1}_vs_{engine2}"
                        try:
                            comparison_metrics[key] = {
                                'cer': cer(texts[engine1], texts[engine2]),
                                'wer': wer(texts[engine1], texts[engine2]),
                                'similarity': normalized_levenshtein(texts[engine1], texts[engine2]),
                                'length_diff': abs(len(texts[engine1]) - len(texts[engine2]))
                            }
                        except Exception as e:
                            comparison_metrics[key] = {'error': str(e)}

        return {
            'results': results,
            'comparison_metrics': comparison_metrics,
            'summary': {
                'engines_tested': len(results),
                'successful_engines': len([r for r in results.values() if r.get('success')]),
                'failed_engines': len([r for r in results.values() if not r.get('success')])
            }
        }

    def calculate_metrics(
        self,
        reference_text: str,
        hypothesis_text: str
    ) -> Dict[str, float]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ OCR

        Args:
            reference_text: –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            hypothesis_text: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not METRICS_AVAILABLE:
            raise RuntimeError("–ú–æ–¥—É–ª—å –º–µ—Ç—Ä–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        return {
            'cer': cer(reference_text, hypothesis_text),
            'wer': wer(reference_text, hypothesis_text),
            'similarity': normalized_levenshtein(reference_text, hypothesis_text),
            'length_reference': len(reference_text),
            'length_hypothesis': len(hypothesis_text),
            'length_ratio': len(hypothesis_text) / len(reference_text) if len(reference_text) > 0 else 0,
            'words_reference': len(reference_text.split()),
            'words_hypothesis': len(hypothesis_text.split())
        }

    def batch_process(
        self,
        image_paths: List[str],
        engine: str = 'PaddleOCR',
        **kwargs
    ) -> List[Dict[str, Any]]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        results = []

        for i, image_path in enumerate(image_paths):
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {i+1}/{len(image_paths)}: {Path(image_path).name}")
            result = self.process_document(
                image_path=image_path,
                engine=engine,
                **kwargs
            )
            results.append(result)

        return results


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    coordinator = OCRCoordinator()

    print("üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ OCR –¥–≤–∏–∂–∫–∏:")
    engines_info = coordinator.get_engine_info()
    for name, info in engines_info.items():
        status = "‚úÖ" if info['available'] else "‚ùå"
        print(f"  {status} {name}: {info['description']}")

    # –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
    test_image = "../data/samples/image.png"
    if Path(test_image).exists():
        print(f"\nüìÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ñ–∞–π–ª–µ: {test_image}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–∏–º –¥–≤–∏–∂–∫–æ–º
        if coordinator.get_available_engines():
            engine = coordinator.get_available_engines()[0]
            result = coordinator.process_document(test_image, engine=engine)

            if result.get('success'):
                print(f"‚úÖ {engine} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª –¥–æ–∫—É–º–µ–Ω—Ç")
                print(f"üìù –¢–µ–∫—Å—Ç: {result['raw_text'][:100]}...")
                print(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ–ª–µ–π: {len(result.get('extracted_fields', {}))}")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ {engine}: {result.get('error')}")

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤–∏–∂–∫–æ–≤
        available = coordinator.get_available_engines()
        if len(available) > 1:
            print(f"\nüîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤–∏–∂–∫–æ–≤: {', '.join(available[:2])}")
            comparison = coordinator.compare_engines(test_image, engines=available[:2])
            print(f"üìä –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {comparison['summary']['successful_engines']}/{comparison['summary']['engines_tested']}")
    else:
        print(f"\n‚ö†Ô∏è  –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_image}")